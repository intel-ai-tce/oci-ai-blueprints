{
  "recipe_id": "llm_inference_cpu",
  "recipe_mode": "service",
  "deployment_name": "vllm-closed-hf-model",
  "recipe_image_uri": "public.ecr.aws/q9t5s3a7/vllm-cpu-release-repo:latest",
  "recipe_node_shape": "VM.Standard3.Flex",
  "recipe_container_env": [
    {
      "key": "HF_TOKEN",
      "value": "<AUTH-TOKEN-HERE>"
    },
    {
      "key": "tensor_parallel_size",
      "value": "2"
    },
    {
      "key": "VLLM_CPU_KVCACHE_SPACE",
      "value": "40"
    },
    {
      "key": "VLLM_CPU_SGL_KERNEL",
      "value": "1"
    },
    {
      "key": "VLLM_RPC_TIMEOUT",
      "value": "100000"
    },
    {
      "key": "VLLM_ENGINE_ITERATION_TIMEOUT_S",
      "value": "120"
    },
    {
      "key": "VLLM_ALLOW_LONG_MAX_MODEL_LEN",
      "value": "1"
    }
  ],
  "recipe_replica_count": 1,
  "recipe_container_port": "8000",
  "recipe_prometheus_enabled": true,
  "recipe_node_pool_size": 1,
  "recipe_node_boot_volume_size_in_gbs": 200,
  "recipe_container_command_args": [
    "--model",
    "meta-llama/Llama-3.2-11B-Vision",
    "--dtype",
    "bfloat16",
    "--distributed-executor-backend",
    "mp",
    "--block-size",
    "128",
    "--trust-remote-code",
    "--enforce-eager",
    "--max-num-batched-tokens",
    "2048",
    "--max-num-seqs",
    "256",
    "--tensor-parallel-size",
    "$(tensor_parallel_size)"
  ],
  "recipe_ephemeral_storage_size": 100,
  "recipe_shared_memory_volume_size_limit_in_mb": 200
}
